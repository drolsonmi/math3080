{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 7 Otaining Data from a File\n",
    "__Math 3080: Fundamentals of Data Science__\n",
    "\n",
    "Reading:\n",
    "* [McKinney, *Python for Data Science*, Chapter 6](https://wesmckinney.com/book/accessing-data)\n",
    "\n",
    "Class notes are found through GitHub. As changes are made, they will automatically be uploaded to GitHub. A link to the repository is on Canvas.\n",
    "\n",
    "-----\n",
    "## Outline\n",
    "* File Requirements\n",
    "  * Description of Variables (in file or as a separate document)\n",
    "* Loading Data from a File\n",
    "  * Column Names\n",
    "  * Headers\n",
    "  * Showing just the head or tail of the data\n",
    "  * Splitting Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Loading Data from File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data needs to be stored in a certain file format to be loaded into Python. Python can handle many, but Pandas is able to load more.\n",
    "* [File types handled by Python - McKinney, Chapter 6](https://wesmckinney.com/book/accessing-data#tbl-table_parsing_functions)\n",
    "\n",
    "Regardless of the file type, we must know what we are dealing with. Consider this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "grades = pd.read_csv(\"../Datasets/grades.csv\")\n",
    "grades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh-oh! Something is wrong. We can see the data, and from the name of the file, it looks like we have some sort of list of grades. We have the names of the students, but we have no idea what each variable in our DataFrame is.\n",
    "\n",
    "Let's look now at a few requirements for good datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Good Rules for Handling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing, take a look at the data. It is always good to see what the data looks like before we try to do anything with it.\n",
    "* [https://github.com/drolsonmi/math3080/blob/main/Datasets/grades.csv](https://github.com/drolsonmi/math3080/blob/main/Datasets/grades.csv)\n",
    "\n",
    "1. Look at your data before loading it\n",
    "2. When you are saving data, make sure there is documentation\n",
    "    * Documentation includes an explanation of what the dataset is, what the columns of the dataset are, and units for each variable.\n",
    "\n",
    "This file has data, but the columns have no labels. When we tried to import earlier, the first line was assumed as a header line and became labels for the columns. To avoid that, we tell Pandas that there is no header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = pd.read_csv('../Datasets/grades.csv', header=None)\n",
    "grades.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this is as far as we can go. Without an explanation of the variables, our dataset is basically useless, we we can't decide what to do with it.\n",
    "\n",
    "Every dataset MUST have some explanation of the variables in our dataset. Very often, this is done with a separate README file. For this dataset, look at the documentation here:\n",
    "* [https://github.com/drolsonmi/math3080/blob/main/Datasets/grades_README.txt](https://github.com/drolsonmi/math3080/blob/main/Datasets/grades_README.txt)\n",
    "\n",
    "Using this, we can update our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = pd.read_csv('../Datasets/grades.csv', header=None)\n",
    "grades.columns = ['Name','Attendance','Homework','Project_Proposal',\n",
    "                   'Project_Checkup','Project_Final','Midterm','Final']\n",
    "\n",
    "# See the first few rows of the data (default=5)\n",
    "grades.head()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, the variables are labeled in the data, as in the following example, though the labels could be in code. Again, the README file should explain what each means.\n",
    "* [https://github.com/drolsonmi/math3080/blob/main/Datasets/grades1.csv](https://github.com/drolsonmi/math3080/blob/main/Datasets/grades1.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = pd.read_csv('../Datasets/grades1.csv') # No Header statement means header=1\n",
    "display(grades.head(4))\n",
    "\n",
    "grades.columns = ['Name','Attendance','Homework','Project_Proposal',\n",
    "                   'Project_Checkup','Project_Final','Midterm','Final']\n",
    "display(grades.head(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, the file is separated by a character other than a comma. Some common separators (a.k.a. delimiters) include:\n",
    "* `;` a semi-colon\n",
    "* `:` a colon\n",
    "* ` ` a space\n",
    "* `\\t` a tab\n",
    "\n",
    "Here's the same dataset, only this time separated by a semicolon (;).\n",
    "* [https://github.com/drolsonmi/math3080/blob/main/Datasets/grades2.csv](https://github.com/drolsonmi/math3080/blob/main/Datasets/grades2.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = pd.read_csv('../Datasets/grades2.csv')\n",
    "grades.columns = ['Name','Attendance','Homework','Project_Proposal',\n",
    "                   'Project_Checkup','Project_Final','Midterm','Final']\n",
    "\n",
    "display(grades.head(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we there is one other way documentation might be provided. We might see the labels *in the file itself*. If we are following good practice, we will open the file before importing the data and see these labels.\n",
    "* [https://github.com/drolsonmi/math3080/blob/main/Datasets/grades3.csv](https://github.com/drolsonmi/math3080/blob/main/Datasets/grades3.csv)\n",
    "\n",
    "In this case, there are extra lines ahead of the data which explain the data itself. But this makes loading the data more difficult. For this, use the `skiprows=` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = pd.read_csv('../Datasets/grades3.csv', skiprows=9)\n",
    "display(grades.head(4))\n",
    "\n",
    "grades.columns = ['Name','Attendance','Homework','Project_Proposal',\n",
    "                   'Project_Checkup','Project_Final','Midterm','Final']\n",
    "display(grades.head(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Loading data from an Excel file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could simply read an excel file just like any other file type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = pd.read_excel('../grades3.xlsx', skiprows=10)\n",
    "grades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, Pandas offers some more functionality. If we use `pd.ExcelFile()` to load the file, then we get an object with all worksheets within the file. We can then choose which one we want to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel = pd.ExcelFile('grades3.xlsx')\n",
    "excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel.sheet_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = excel.parse(sheet_name='grades3', skiprows=10)\n",
    "grades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Loading data from a file on the Internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a file from the internet is just like reading it from a file. Just use a web directory instead of a file directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = pd.read_csv('https://raw.githubusercontent.com/drolsonmi/math3080/main/Datasets/data_science_salaries.csv')\n",
    "salaries.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "## Web Scraping\n",
    "Web scraping is a very important tool and technique. A lot of the data is on the internet, set up as a table on an HTML page.\n",
    "\n",
    "If you are like me, you have handled HTML tables by going to the webpage, copying the table, putting them into an excel file, then work for an hour or two trying to format the data to a format you can use. This is obnoxious and takes way too much time.\n",
    "\n",
    "The idea of __web scraping__ is to go through the file itself and identify any tables in the file. Most commonly, we apply web scraping to *HTML* and *xml* files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scraping with HTML\n",
    "In Pandas, we have a `pd.read_html()` function. This will take the given HTML file and look for `<table>` tags. If it finds one, then it can decode the table and save it as a DataFrame.\n",
    "* to read a table from an html file, install the `lxml` package\n",
    "\n",
    "What if there are multiple tables on the webpage? The `pd.read_html()` command will find all `<table>` tags and convert all of them into a DataFrame, saving them all into an array. So, the output of the `pd.read_html()` command is an array. To access the table you want, just call that table from the array.\n",
    "\n",
    "Look at the [author's FDIC example](https://raw.githubusercontent.com/wesm/pydata-book/3rd-edition/examples/fdic_failed_bank_list.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banks = pd.read_html('https://raw.githubusercontent.com/wesm/pydata-book/3rd-edition/examples/fdic_failed_bank_list.html')\n",
    "display(banks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scraping with XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
