{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a64d8ebd-06bd-4155-9657-115cd5f9948a",
   "metadata": {},
   "source": [
    "# 01 Introduction to Data Science\n",
    "__Math 3080: Fundamentals of Data Science__\n",
    "\n",
    "__Outline__\n",
    "1. What is Data Science? What is Machine Learning?\n",
    "2. The Machine Learning Process\n",
    "3. A setup of the Data Science courses\n",
    "4. The Nature of Data\n",
    "\n",
    "__Reading__ \n",
    "* Grus, *Data Science from Scratch*, Chapter 1\n",
    "* [Brunton video: The Nature of Data](https://youtu.be/OAB2bHsee9Y)\n",
    "* [Leskovec](https://www.mmds.org), 1.1-1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f94845-9d86-4d77-b13b-16f24c502518",
   "metadata": {},
   "source": [
    "-----\n",
    "## What is Data Science?\n",
    "* What is Statistics?\n",
    "  * Answering a question by infering information from Data\n",
    "    * It is important to ask the \"right\" questions\n",
    "    * Determine what data is needed to answer the question\n",
    "  * Who won the election?\n",
    "  * Confidence Interval and Hypothesis Test\n",
    "* What is Data Science?\n",
    "  * The Science of how to best handle data\n",
    "    * *Brunton*: How to collect, clean, store, visualize, and model data\n",
    "    * *Leskovec*: How to use the most powerful hardware, the most powerful programming systems, and the most efficient algorithms to solve problems in science, commerce, healthcare, government, the humanities, and many other fields of human endeavor.\n",
    "  * Field is changing quickly\n",
    "  * Have been doing this for 1,000's of years\n",
    "  * Stages of Data Science\n",
    "    1. Gathering of Data (Collecting, curating, cleaning)\n",
    "        * Tico Bray - Astronomical observations\n",
    "    2. Analysis of Data (visualization, analysis, modeling (machine learning))\n",
    "        * Johannes Kepler - Astronomical models\n",
    "    3. Explanation of Data (Cleaning and Presenting the visuals with explanations)\n",
    "        * Isaac Newton - Laws of Motion\n",
    "        * Based his laws on the \"preponderance of the evidence\"\n",
    "  * Data Science spans all three stages, but primarily the Gathering and Analysis stages\n",
    "  * Machine learning takes up Kepler's role - come up with a general model to explain how things work\n",
    "  * Most of our work as data scientists is in the first stage - collecting and cleaning the data\n",
    "    * Bad data = Bad science\n",
    "* What is a Data Scientist?\n",
    "  * This can be difficult to answer, and the answer depends on what the person is trying to do\n",
    "      * Someone who extracts insights from messy data\n",
    "  * Most experts follow a T-shape (general knowledge of many fields, but a depth of knowledge in one field)\n",
    "  * Data scientists need to follow pi-model (depth in main field, but a second depth in data science as well)\n",
    "  * Important aspects of Data Science\n",
    "    * Reproducibility "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2333e901",
   "metadata": {},
   "source": [
    "-----\n",
    "## The Data Science and Machine Learning process\n",
    "* Data pre-processing (MATH 3080)\n",
    "\t* Obtain and load the data\n",
    "\t* Clean the data\n",
    "\t* Analyze the data\n",
    "\t* Split into training and testing sets\n",
    "* Modeling (MATH 3480)\n",
    "\t* Build and Train the model\n",
    "\t* Make predictions\n",
    "* Evaluation (MATH 3480)\n",
    "\t* Calculate performance metrics\n",
    "    * Determine if the model is good\n",
    "\n",
    "Demonstration of the process:\n",
    "* __3480_00a_Demo.ipynb__\n",
    "* __3480_00a_Demo2.ipynb__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7579d44f-595d-4fc1-b494-cc57e62d272d",
   "metadata": {},
   "source": [
    "-----\n",
    "## Setup of courses\n",
    "We are going to learn Data Science in 3 courses\n",
    "\n",
    "* __Math 2080 Applied Data Science / Math 3080 Foundations of Data Science__\n",
    "  * How to obtain data\n",
    "  * How to clean/edit data\n",
    "  * How to graph data\n",
    "  * Some work on models and Machine Learning\n",
    "* __Math 3280 Data Mining__\n",
    "  * How to manage large datasets and files\n",
    "  * Server management\n",
    "* __Math 3480 Machine Learning__\n",
    "  * How to train computers to make predictions based on previously obtained data\n",
    "\n",
    "\n",
    "For Math 2080/3080, we have two things we have to learn, but not enough time to learn it all:\n",
    "\n",
    "1. Fundamentals of Data Science\n",
    "2. Python programming\n",
    "    * The point of this course is to learn the fundamentals of data science\n",
    "    * Python is just a tool that we are going to use\n",
    "    * Homework assignments will be courses within DataCamp to help learn the language so that we can focus on the fundamentals in the classroom\n",
    "    * In addition to DataCamp, we also have Chapter 2 of the Grus textbook, as well as nearly the entire *Python for Data Analysis* textbook.\n",
    "    \n",
    "__How much Python experience does the class have?__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8ff1a3-d762-4be0-a8a7-6970b9b1f1fc",
   "metadata": {},
   "source": [
    "## Textbooks\n",
    "I will be pulling from 3 textbooks, all of which are free:\n",
    "* [McKinney, Wes, *Python for Data Science*, 3rd Edition, 2022.](https://wesmckinney.com/book/)\n",
    "* [Irizarry, Rafael, *Introduction to Data Science*, 2020.](https://rafalab.dfci.harvard.edu/dsbook-part-1/)\n",
    "\n",
    "We may look into the textbooks for Math 3280 and Math 3480, but I will show you those if/when needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201ee56a-a774-49bb-a748-53521c61f7c4",
   "metadata": {},
   "source": [
    "## DataCamp\n",
    "* Everyone will be sent an email with an invitation to our classroom on DataCamp\n",
    "* Homework assignments will be administered on DataCamp\n",
    "  * Projects will be administered every 2-3 weeks to apply what you are learning\n",
    "* In addition to homework, you will have access to other courses, certification training (and certification exams), competitions, etc.\n",
    "  * Only good for 6 months\n",
    "  * Those continuing on to Math 3280 will receive another invitation to that course to retain access to DataCamp materials"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fa34cc3f",
   "metadata": {},
   "source": [
    "-----\n",
    "### After Class\n",
    "* Admit all students to *DataCamp* classroom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41339582",
   "metadata": {},
   "source": [
    "-----\n",
    "## More about Data Science\n",
    "Before computers were around, statisticians were the people who would take data and infer information from it. This process of digging deep into data was called \"data dredging\", and was used as a derogatory term for the rather unpleasant task of digging deep into data. Another term used was \"data mining\". Either way, it wasn't an appealing field as the researcher had to find results based on data that wasn't there. Now, the algorithms used are much more sofisticated and more accurate. As such, it has become a popular field that we now call \"data science\".\n",
    "\n",
    "Our series of courses are divided into three semesters:\n",
    "1. Math 3080: Foundations of Data Science\n",
    "2. Math 3280: Data Mining\n",
    "3. Math 3480: Machine Learning\n",
    "\n",
    "These courses really are the same, just looking at different aspects of Data Science. Math 3080 is going to be a review of Statistics and Math principles, then 3280 and 3480 will dig deeper. Here's how we separate these courses:\n",
    "1. In Math 3080, we review the statistics and mathematics needed to understand Data Science. Here, we learn about the foundational material needed to understand goals, objectives, and processes in the field of Data Science.\n",
    "2. In Math 3280, we will look at challenges of having large amounts of data. We will also learn algorithms that simplifies the way we manage and work with large amounts of data.\n",
    "3. In Math 3480, we will look at ways to take the data and create models with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416da904",
   "metadata": {},
   "source": [
    "## Asking the right questions\n",
    "Ultimately, we want to find the best algorithm to model data. Once we find the best algorithm, we can apply it to the data in order to answer questions and use those answers to model future events. As such, it is important for us to get the right data to answer the correct questions, and to ask the right questions so we know what data we need.\n",
    "\n",
    "Following are some common questions that should be asked when preparing to start a project:\n",
    "* Does the past represent the future?\n",
    "* What do I want to model?\n",
    "* How will the model be used?\n",
    "* What data do I need? What data do I have?\n",
    "* How hard is it to get the data?\n",
    "\n",
    "Questions lead to what data you obtain, and data determines what questions you can answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03842eec",
   "metadata": {},
   "source": [
    "## Data\n",
    "A common mentality is that more data is better. Data Scientists look for __Big Data__, getting as much information as possible to make as good of a model as possible. However, sometimes too much data can ruin the outcome (See the limitations section below). What we need is __Smart Data__, where very specific data are collected.\n",
    "\n",
    "What kind of data are there?\n",
    "* Types of Data\n",
    "  * Numerical data\n",
    "    * Continuous\n",
    "    * Discrete\n",
    "  * Categorical data\n",
    "    * Ordinal data (Also discrete)\n",
    "    * Nominal data\n",
    "* Dimensional Data\n",
    "  * High Dimensional data\n",
    "    * Many degrees of freedom\n",
    "    * images\n",
    "    * Star charts\n",
    "\n",
    "    | Time | ID  | azimuth | declination | magnitude | distance |\n",
    "    | ---- | --- | ------- | ----------- | --------- | -------- |\n",
    "    | .... | ... | ....... | ........... | ......... | ........ |\n",
    "\n",
    "  * Low Dimensional data\n",
    "\n",
    "    | Time | magnitude |\n",
    "    | ---- | --------- |\n",
    "    | .... | ......... |\n",
    "    \n",
    "* Labeled\n",
    "  * Supervised data\n",
    "    * Comes with labels to help train the data\n",
    "  * Unsupervised data\n",
    "    * Does not have labels\n",
    "    * Model has to find its own categories\n",
    "* How many examples\n",
    "  * Many examples\n",
    "    * Labeled images\n",
    "    * Time-series measurements with fine precision (one measurement every 0.1 sec for 10 hrs)\n",
    "    * Great for Neural Networks\n",
    "  * Few examples\n",
    "    * Things limited by cost or availability, such as sequencing genomes\n",
    "    * Often called Deep Data (High dimensions, Few examples)\n",
    "* Temporal or Physical\n",
    "  * Temporal - time series\n",
    "  * Physical - describing something in the real world at one specific point in time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a60f02b",
   "metadata": {},
   "source": [
    "## Other concerns with Data\n",
    "* How do you organize the data?\n",
    "* How do you clean the data?\n",
    "* How do you store the data?\n",
    "* How do you collect the data?\n",
    "* What algorithms can I use?\n",
    "* Do I need a supercomputer or is a laptop sufficient?\n",
    "\n",
    "The different types of data lead to other questions:\n",
    "* What are the inputs?\n",
    "* What are the outputs?\n",
    "\n",
    "The inputs and outputs then determine what questions we should be asking. So, it is a big cycle:\n",
    "* Questions \n",
    "*   -> Data (big or smart)\n",
    "*   -> What types of data do we collect?\n",
    "*   -> What inputs/outputs can we/do we want?\n",
    "*   -> What questions can we ask\n",
    "*   -> (Cycle repeats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5e706a",
   "metadata": {},
   "source": [
    "## Limitations to the Data\n",
    "One would think that having more data will give better results. However, having too much data could actually give false results. Consider this example:\n",
    "\n",
    "<!--You need 5 people to transport a material for a chemistry experiment. It is harmless, except for the 0.1% of people who have a severe allergy to a chemical in the material. If you have 1,000 people to choose from, then statistically, only 1 person should have this allergy.\n",
    "* From the 1,000 people, take a sample of 5 people. There are $8.25*10^12$ different possible groups.\n",
    "* If you take the average allergy level of the group, to see if it is acceptable. You determine that -->\n",
    "\n",
    "In the *Mining of Massive Datasets* book by Leskovec, an example is given of something called *Bonferroni's Principle* (section 1.2.3). Assume you are searching for 2 people who you know are meeting together at hotels to plan something malicious. You decide to look for them at these hotels. Your search begins with these assumptions:\n",
    "1. There are one billion people who are suspects\n",
    "2. Everyone goes to a hotel one day in 100\n",
    "3. A hotel holds 100 people, so there are 100,000 hotels to hold the 1% of a billion people visiting a hotel on a given day\n",
    "4. Records are examined for 1000 days\n",
    "\n",
    "After analyzing the probabilities and counting the number of possible times 2 people end up at the same hotel on the same night, you find that there are 250,000 positive matches. But only one is correct, so that gives 249,998 false positives (Type I error).\n",
    "\n",
    "So, although Big Data could be helpful, we have to be careful about having too much data. It may be wiser to instead look at __smart data__."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "R",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
