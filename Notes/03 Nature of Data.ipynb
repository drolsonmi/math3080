{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dfb7c59-efbc-4a87-9d77-cc49571bf982",
   "metadata": {},
   "source": [
    "# 03 Nature of Data\n",
    "__Math 3080: Fundamentals of Data Science__\n",
    "\n",
    "Math 3080-specific lecture\n",
    "\n",
    "Reading: \n",
    "* [Brunton video: The Nature of Data](https://youtu.be/OAB2bHsee9Y)\n",
    "* Leskovec, 1.1-1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afeb8d8e-efa0-4017-85b7-a59cf065692c",
   "metadata": {},
   "source": [
    "## More about Data Science\n",
    "Before computers were around, statisticians were the people who would take data and infer information from it. This process of digging deep into data was called \"data dredging\", and was used as a derogatory term for the rather unpleasant task of digging deep into data. Another term used was \"data mining\". Either way, it wasn't an appealing field as the researcher had to find results based on data that wasn't there. Now, the algorithms used are much more sofisticated and more accurate. As such, it has become a popular field that we now call \"data science\".\n",
    "\n",
    "Our series of courses are divided into three semesters:\n",
    "1. Math 3080: Foundations of Data Science\n",
    "2. Math 3280: Data Mining\n",
    "3. Math 3480: Machine Learning\n",
    "\n",
    "These courses really are the same, just looking at different aspects of Data Science. Math 3080 is going to be a review of Statistics and Math principles, then 3280 and 3480 will dig deeper. Here's how we separate these courses:\n",
    "1. In Math 3080, we review the statistics and mathematics needed to understand Data Science. Here, we learn about the foundational material needed to understand goals, objectives, and processes in the field of Data Science.\n",
    "2. In Math 3280, we will look at challenges of having large amounts of data. We will also learn algorithms that simplifies the way we manage and work with large amounts of data.\n",
    "3. In Math 3480, we will look at ways to take the data and create models with it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e5767a-82c7-4ebd-9b90-3683a7dc5bcd",
   "metadata": {},
   "source": [
    "## Asking the right questions\n",
    "Ultimately, we want to find the best algorithm to model data. Once we find the best algorithm, we can apply it to the data in order to answer questions and use those answers to model future events. As such, it is important for us to get the right data to answer the correct questions, and to ask the right questions so we know what data we need.\n",
    "\n",
    "Following are some common questions that should be asked when preparing to start a project:\n",
    "* Does the past represent the future?\n",
    "* What do I want to model?\n",
    "* How will the model be used?\n",
    "* What data do I need? What data do I have?\n",
    "* How hard is it to get the data?\n",
    "\n",
    "Questions lead to what data you obtain, and data determines what questions you can answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb9d6fc-759b-42d5-a9f1-c61f2f58fe5a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data\n",
    "A common mentality is that more data is better. Data Scientists look for __Big Data__, getting as much information as possible to make as good of a model as possible. However, sometimes too much data can ruin the outcome (See the limitations section below). What we need is __Smart Data__, where very specific data are collected.\n",
    "\n",
    "What kind of data are there?\n",
    "* Types of Data\n",
    "  * Numerical data\n",
    "    * Continuous\n",
    "    * Discrete\n",
    "  * Categorical data\n",
    "    * Ordinal data (Also discrete)\n",
    "    * Nominal data\n",
    "* Dimensional Data\n",
    "  * High Dimensional data\n",
    "    * Many degrees of freedom\n",
    "    * images\n",
    "    * Star charts\n",
    "\n",
    "    | Time | ID  | azimuth | declination | magnitude | distance |\n",
    "    | ---- | --- | ------- | ----------- | --------- | -------- |\n",
    "    | .... | ... | ....... | ........... | ......... | ........ |\n",
    "\n",
    "  * Low Dimensional data\n",
    "\n",
    "    | Time | magnitude |\n",
    "    | ---- | --------- |\n",
    "    | .... | ......... |\n",
    "    \n",
    "* Labeled\n",
    "  * Supervised data\n",
    "    * Comes with labels to help train the data\n",
    "  * Unsupervised data\n",
    "    * Does not have labels\n",
    "    * Model has to find its own categories\n",
    "* How many examples\n",
    "  * Many examples\n",
    "    * Labeled images\n",
    "    * Time-series measurements with fine precision (one measurement every 0.1 sec for 10 hrs)\n",
    "    * Great for Neural Networks\n",
    "  * Few examples\n",
    "    * Things limited by cost or availability, such as sequencing genomes\n",
    "    * Often called Deep Data (High dimensions, Few examples)\n",
    "* Temporal or Physical\n",
    "  * Temporal - time series\n",
    "  * Physical - describing something in the real world at one specific point in time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044c8e23-e0ee-42fa-b082-ef7a776b5280",
   "metadata": {},
   "source": [
    "## Other concerns with Data\n",
    "* How do you organize the data?\n",
    "* How do you clean the data?\n",
    "* How do you store the data?\n",
    "* How do you collect the data?\n",
    "* What algorithms can I use?\n",
    "* Do I need a supercomputer or is a laptop sufficient?\n",
    "\n",
    "The different types of data lead to other questions:\n",
    "* What are the inputs?\n",
    "* What are the outputs?\n",
    "\n",
    "The inputs and outputs then determine what questions we should be asking. So, it is a big cycle:\n",
    "* Questions \n",
    "*   -> Data (big or smart)\n",
    "*   -> What types of data do we collect?\n",
    "*   -> What inputs/outputs can we/do we want?\n",
    "*   -> What questions can we ask\n",
    "*   -> (Cycle repeats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a86ecd2-806e-4b5c-9a16-b2ba2037df1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Limitations to the Data\n",
    "One would think that having more data will give better results. However, having too much data could actually give false results. Consider this example:\n",
    "\n",
    "<!--You need 5 people to transport a material for a chemistry experiment. It is harmless, except for the 0.1% of people who have a severe allergy to a chemical in the material. If you have 1,000 people to choose from, then statistically, only 1 person should have this allergy.\n",
    "* From the 1,000 people, take a sample of 5 people. There are $8.25*10^12$ different possible groups.\n",
    "* If you take the average allergy level of the group, to see if it is acceptable. You determine that -->\n",
    "\n",
    "In the *Mining of Massive Datasets* book by Leskovec, an example is given of something called *Bonferroni's Principle* (section 1.2.3). Assume you are searching for 2 people who you know are meeting together at hotels to plan something malicious. You decide to look for them at these hotels. Your search begins with these assumptions:\n",
    "1. There are one billion people who are suspects\n",
    "2. Everyone goes to a hotel one day in 100\n",
    "3. A hotel holds 100 people, so there are 100,000 hotels to hold the 1% of a billion people visiting a hotel on a given day\n",
    "4. Records are examined for 1000 days\n",
    "\n",
    "After analyzing the probabilities and counting the number of possible times 2 people end up at the same hotel on the same night, you find that there are 250,000 positive matches. But only one is correct, so that gives 249,999 false positives (Type I error).\n",
    "\n",
    "So, although Big Data could be helpful, we have to be careful about having too much data. It may be wiser to instead look at __smart data__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83b2d2d-d89f-4f2c-9db9-74a559ae81a6",
   "metadata": {},
   "source": [
    "-----\n",
    "## Additional topics to cover\n",
    "### Function Documentation - __Docstrings__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95544392-aa65-439f-9b46-cb18342e4135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_one(x):\n",
    "    \"\"\" Here is a description of the function. \n",
    "    And a second line to the description. \"\"\"\n",
    "    return x-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8a1713e-1b80-4fbd-adc0-60face9ca180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtract_one(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da8eb01e-0cce-40aa-a9b0-4bd4dfa209a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m \u001b[0msubtract_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "Here is a description of the function. \n",
      "And a second line to the description. \n",
      "\u001b[1;31mFile:\u001b[0m      c:\\users\\drols\\appdata\\local\\temp\\ipykernel_7020\\2951862098.py\n",
      "\u001b[1;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "subtract_one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcbf9001-44f7-4a93-81cd-f6537b788bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "print(value, ..., sep=' ', end='\\n', file=sys.stdout, flush=False)\n",
       "\n",
       "Prints the values to a stream, or to sys.stdout by default.\n",
       "Optional keyword arguments:\n",
       "file:  a file-like object (stream); defaults to the current sys.stdout.\n",
       "sep:   string inserted between values, default a space.\n",
       "end:   string appended after the last value, default a newline.\n",
       "flush: whether to forcibly flush the stream.\n",
       "\u001b[0;31mType:\u001b[0m      builtin_function_or_method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103773fd-3fac-4fb1-b791-7e8b5f3b323e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a2e291-650d-4b6b-9cc4-d46f6265c12b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10 (main, Jan 15 2022, 11:40:53) \n[Clang 13.0.0 (clang-1300.0.29.3)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
